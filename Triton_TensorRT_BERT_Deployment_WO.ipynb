{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd5bd9-53b4-47bc-9cdf-95685c53e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires GPU Strictly. This tutorial was implemented with g5.2xlarge Notebook Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13192e3c-bf34-4600-b358-bba67989bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9a789-0d00-4b8f-ba19-57df50fc4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers tritonclient[http]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b45ca-a457-4fd3-8328-a45348f9d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import boto3, json, sagemaker, time\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "role = get_execution_role()\n",
    "client = boto3.client(\"sagemaker-runtime\")\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041edc88-1ce1-4255-ab0c-e7f0c5e50319",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33387dd2-5952-4921-9ddb-28eb259ff9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25bebbb-341e-447b-9bf1-28fab5afe70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:23.02-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996aba8-b273-44ab-89c6-4388c4865f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3cdd7-94c7-4fbd-91ee-898b04954c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_tokenizer():\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    enc = get_tokenizer()\n",
    "    encoded_text = enc(text, padding=\"max_length\", max_length=128)\n",
    "    return encoded_text[\"input_ids\"], encoded_text[\"attention_mask\"]\n",
    "\n",
    "\n",
    "def _get_sample_tokenized_text_binary(text, input_names, output_names):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    inputs.append(httpclient.InferInput(input_names[0], [1, 128], \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], [1, 128], \"INT32\"))\n",
    "    indexed_tokens, attention_mask = tokenize_text(text)\n",
    "\n",
    "    indexed_tokens = np.array(indexed_tokens, dtype=np.int32)\n",
    "    indexed_tokens = np.expand_dims(indexed_tokens, axis=0)\n",
    "    inputs[0].set_data_from_numpy(indexed_tokens, binary_data=True)\n",
    "\n",
    "    attention_mask = np.array(attention_mask, dtype=np.int32)\n",
    "    attention_mask = np.expand_dims(attention_mask, axis=0)\n",
    "    inputs[1].set_data_from_numpy(attention_mask, binary_data=True)\n",
    "\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[1], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_pt(text):\n",
    "    return _get_sample_tokenized_text_binary(\n",
    "        text, [\"INPUT__0\", \"INPUT__1\"], [\"OUTPUT__0\", \"1634__1\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_trt(text):\n",
    "    return _get_sample_tokenized_text_binary(\n",
    "        text, [\"token_ids\", \"attn_mask\"], [\"output\", \"pooled_output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e177c-ad82-4e6b-aefe-26f4f9d6e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37f976-7fe9-4b55-99d1-d2bfae0bf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile workspace/generate_models.sh\n",
    "#!/bin/bash\n",
    "python -m pip install transformers==4.26.1\n",
    "python onnx_exporter.py\n",
    "\n",
    "trtexec --onnx=model.onnx --saveEngine=model_bs16.plan --minShapes=token_ids:1x128,attn_mask:1x128 --optShapes=token_ids:16x128,attn_mask:16x128 --maxShapes=token_ids:128x128,attn_mask:128x128 --fp16 --verbose --workspace=14000 | tee conversion_bs16_dy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1969b0-6b83-465e-953d-ea92bfe853de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile workspace/onnx_exporter.py\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--save\", default=\"model.onnx\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "    bs = 1\n",
    "    seq_len = 128\n",
    "    dummy_inputs = (torch.randint(1000, (bs, seq_len)), torch.zeros(bs, seq_len, dtype=torch.int))\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_inputs,\n",
    "        args.save,\n",
    "        export_params=True,\n",
    "        opset_version=10,\n",
    "        input_names=[\"token_ids\", \"attn_mask\"],\n",
    "        output_names=[\"output\",\"pooled_output\"],\n",
    "        dynamic_axes={\"token_ids\": [0, 1], \"attn_mask\": [0, 1], \"output\": [0]},\n",
    "    )\n",
    "\n",
    "    print(\"Saved {}\".format(args.save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545f7cf-09bc-47c2-af0f-dc9758e804cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!docker run --gpus=all --rm -it \\\n",
    "            -v `pwd`/workspace:/workspace nvcr.io/nvidia/pytorch:23.02-py3 \\\n",
    "            /bin/bash generate_models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5de88e-bc1c-476e-aa15-3a2f7dcdea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repo_0/bert_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2101568-21df-4098-ba85-70d281413097",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model_repo_0/bert_0/config.pbtxt\n",
    "name: \"bert\"\n",
    "platform: \"tensorrt_plan\"\n",
    "max_batch_size: 128\n",
    "input [\n",
    "  {\n",
    "    name: \"token_ids\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  },\n",
    "  {\n",
    "    name: \"attn_mask\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [128]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"output\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [128, 768]\n",
    "  },\n",
    "  {\n",
    "    name: \"pooled_output\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [768]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}\n",
    "dynamic_batching {\n",
    "  preferred_batch_size: 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a611b15-4eb3-4218-92fd-f9743d46118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model_repo_0/bert_0/1/\n",
    "!cp workspace/model_bs16.plan model_repo_0/bert_0/1/model.plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119d9c6-4c8c-478a-8c19-8853db61681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "N = 5\n",
    "prefix = \"bert-mme\"\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    prefix = f\"{default_bucket_prefix}/{prefix}\"\n",
    "    \n",
    "model_repo_base = \"model_repo\"\n",
    "\n",
    "\n",
    "# Get model names from model_repo_0\n",
    "model_names = [\n",
    "    name\n",
    "    for name in os.listdir(f\"{model_repo_base}_0\")\n",
    "    if os.path.isdir(f\"{model_repo_base}_0/{name}\")\n",
    "]\n",
    "\n",
    "for i in range(N):\n",
    "    # Make copy of previous model repo, increment # id\n",
    "    shutil.copytree(f\"{model_repo_base}_0\", f\"{model_repo_base}_{i+1}\")\n",
    "    time.sleep(5)\n",
    "    for name in model_names:\n",
    "        model_dirs_path = f\"{model_repo_base}_{i+1}/{name}\"\n",
    "\n",
    "        # Open each model's config file to increment model # id there\n",
    "        fin = open(f\"{model_dirs_path}/config.pbtxt\", \"rt\")\n",
    "        data = fin.read()\n",
    "        data = data.replace(name, name[:-1] + str(i + 1))\n",
    "        fin.close()\n",
    "        fin = open(f\"{model_dirs_path}/config.pbtxt\", \"wt\")\n",
    "        fin.write(data)\n",
    "        fin.close()\n",
    "\n",
    "        # Change model directory name to match new config\n",
    "        os.rename(model_dirs_path, model_dirs_path[:-1] + str(i + 1))\n",
    "        time.sleep(2)\n",
    "\n",
    "    if i == 0:\n",
    "        tar_file_name = f\"bert-{i}.tar.gz\"\n",
    "        model_repo_target = f\"{model_repo_base}_{i}/\"\n",
    "        !tar -C $model_repo_target -czf $tar_file_name .\n",
    "        sagemaker_session.upload_data(path=tar_file_name, key_prefix=prefix)\n",
    "\n",
    "    tar_file_name = f\"bert-{i+1}.tar.gz\"\n",
    "    model_repo_target = f\"{model_repo_base}_{i+1}/\"\n",
    "    !tar -C $model_repo_target -czf $tar_file_name .\n",
    "    sagemaker_session.upload_data(path=tar_file_name, key_prefix=prefix)\n",
    "    !sudo rm -r \"$tar_file_name\" \"$model_repo_target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e048102-8bed-4412-a125-63e7d8816b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model_name = \"triton-nlp-bert-trt-mme-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "model_data_uri = f\"s3://{bucket}/{prefix}/\"\n",
    "container = {\n",
    "    \"Image\": triton_image_uri,\n",
    "    \"ModelDataUrl\": model_data_uri,\n",
    "    #     \"Environment\": {\"SAGEMAKER_TRITON_DEFAULT_MODEL_NAME\": \"bert\"},\n",
    "    \"Mode\": \"MultiModel\",\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=sm_model_name, ExecutionRoleArn=role, PrimaryContainer=container\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92a5a0-4d12-48a4-852c-939a2ea6647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = \"triton-nlp-bert-trt-mme-\" + time.strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    ")\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g5.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": sm_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd6504-d412-403a-8503-1e9664efedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"triton-nlp-bert-trt-mme-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6168e-503e-47b9-958d-334ab52c4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4de0b-ac52-4973-a177-b5216b321f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "input_ids, attention_mask = tokenize_text(text_triton)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"token_ids\", \"shape\": [1, 128], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"attn_mask\", \"shape\": [1, 128], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i in range(N):\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/octet-stream\",\n",
    "        Body=json.dumps(payload),\n",
    "        TargetModel=f\"bert-{i}.tar.gz\",\n",
    "    )\n",
    "\n",
    "    print(json.loads(response[\"Body\"].read().decode(\"utf8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b957294-ba4b-4825-b1be-8602edbd17d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_sm = \"Amazon SageMaker helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML.\"\n",
    "request_body, header_length = get_sample_tokenized_text_binary_trt(text_sm)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "        header_length\n",
    "    ),\n",
    "    Body=request_body,\n",
    "    TargetModel=\"bert-0.tar.gz\",\n",
    ")\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "# Read response body\n",
    "result = httpclient.InferenceServerClient.parse_response_body(\n",
    "    response[\"Body\"].read(), header_length=int(header_length_str)\n",
    ")\n",
    "# print(response)\n",
    "# print(result)\n",
    "output0_data = result.as_numpy(\"output\")\n",
    "output1_data = result.as_numpy(\"pooled_output\")\n",
    "print(output0_data)\n",
    "print(output1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fa773-d472-4bac-912b-a26187f16c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm.delete_model(ModelName=sm_model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
